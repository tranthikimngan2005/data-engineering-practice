import requests
from bs4 import BeautifulSoup
import pandas as pd
URL = "https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/"
TARGET_DATETIME = "2024-01-19 10:27"

def get_file_link():
    response = requests.get(URL)
    soup = BeautifulSoup(response.text, 'html.parser')

    for row in soup.find_all('tr'):
        if TARGET_DATETIME in row.text:
            return row.find('a')['href']
    return None

def download_file(file_link):
    file_url = URL + file_link
    response = requests.get(file_url)
    local_filename = "weather_data.csv"
    with open(local_filename, 'wb') as f:
        f.write(response.content)
    return local_filename

def analyze_file(filename):
    try:
        df = pd.read_csv(filename)
        if 'HourlyDryBulbTemperature' not in df.columns:
            print("KhÃ´ng tÃ¬m tháº¥y cá»™t HourlyDryBulbTemperature.")
            print(f"CÃ¡c cá»™t hiá»‡n cÃ³: {df.columns.tolist()}")
            return

        max_temp = df['HourlyDryBulbTemperature'].max()
        hottest_records = df[df['HourlyDryBulbTemperature'] == max_temp]
        print("ğŸ”º CÃ¡c báº£n ghi cÃ³ nhiá»‡t Ä‘á»™ cao nháº¥t:")
        print(hottest_records)
    except Exception as e:
        print(f"ÄÃ£ xáº£y ra lá»—i khi Ä‘á»c file: {e}")

def main():
    print("ğŸ” Äang tÃ¬m file theo ngÃ y chá»‰nh sá»­a...")
    file_link = get_file_link()
    if file_link:
        print(f"ğŸ“„ ÄÃ£ tÃ¬m tháº¥y file: {file_link}")
        filename = download_file(file_link)
        print(f"â¬‡ï¸ ÄÃ£ táº£i vá» file: {filename}")
        analyze_file(filename)
    else:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file vá»›i thá»i gian Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh.")

if __name__ == "__main__":
    main()
